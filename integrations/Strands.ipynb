{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f38e32e-1623-46f4-a724-c3f9cd73bcd5",
   "metadata": {},
   "source": [
    "# Using Writer with AWS Strands Agents\n",
    "\n",
    "This notebook demonstrates how to build an agent using the Strands Agents SDK with [WRITER’s models](https://dev.writer.com/home/integrations/strands#available-models).\n",
    "\n",
    "Strands Agents SDK from AWS is an open-source framework that enables developers to build and deploy AI agents using a model-driven approach. This integration allows you to use Writer models within the Strands agent ecosystem, from local development to production deployment.\n",
    "\n",
    "Support for running WRITER models through **Amazon Bedrock with Strands** is also available and is documented separately.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before getting started, you'll need:\n",
    "\n",
    "- A [Writer AI Studio](https://app.writer.com/register) account\n",
    "- An API key, which you can obtain by following the [API Quickstart](https://dev.writer.com/api-guides/quickstart)\n",
    "\n",
    "\n",
    "## Key concepts (how it works)\n",
    "\n",
    "- Use Strands’ `Agent` class to create a self‑contained agent that interacts with a language model and optionally calls tools.\n",
    "- WRITER’s Palmyra models (e.g., `palmyra-x5`, `palmyra-creative`) can be plugged into Strands via the WriterModel integration.\n",
    "- In addition to direct WRITER API usage, the same Strands agent pattern can be used with **WRITER models hosted on Amazon Bedrock**.\n",
    "\n",
    "## Setup\n",
    "To use Writer models with Strands Agents, install the optional Writer dependency along with the [Strands Agents Tools package](https://github.com/strands-agents/tools):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd58d9d-d179-46d5-a3da-9ee705bb40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'strands-agents[writer]'\n",
    "%pip install strands-agents-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5189393e-8531-4216-b593-066843ba4515",
   "metadata": {},
   "source": [
    "Next, set the `WRITER_API_KEY` environment variable. It is recommended to set this value in a `.env` file in the root of the project; however, this tutorial sets it directly as an environment variable if a `.env` file is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481838d0-4acb-496a-8dc4-301b1fdc0c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Writer API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"WRITER_API_KEY\"):\n",
    "    os.environ[\"WRITER_API_KEY\"] = getpass.getpass(\"Enter your Writer API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47c84a-25cb-484d-944c-d87ed2eac1b0",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Initialize a Strands agent using a Palmyra model from WRITER.\n",
    "\n",
    "### Choose a Writer model\n",
    "\n",
    "Import `WriterModel` from the Strands integration and specify a [model ID](https://dev.writer.com/home/integrations/strands#available-models) (for example, `palmyra‑x5`, `palmyra‑creative`, `palmyra‑med`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d5e483-97ba-4819-b0ff-a004cb929864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models.writer import WriterModel\n",
    "\n",
    "writer_model = WriterModel(\n",
    "    model_id=\"palmyra-x5\"  # or other Palmyra model like palmyra-creative, palmyra-fin, etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa344b-6cb0-4f4f-b7cb-f00d4c092704",
   "metadata": {},
   "source": [
    "### Configure tools\n",
    "\n",
    "Define a list of tools to pass to the agent, such as a calculator or HTTP request tool.\n",
    "\n",
    "> The `calculator` tool shown in this example is a prebuilt tool from the [`strands_tools` package](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/example-tools-package/). You can use existing tools from `strands_tools`, or define custom tools—see the [Python Tools](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/tools/python-tools/?h=python+tools) documentation for guidance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451b887-6700-44a0-969a-e59424e2cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands_tools import calculator\n",
    "\n",
    "tools = [calculator]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da399e3f-61fb-455e-b9ee-b4ba0c1a74dc",
   "metadata": {},
   "source": [
    "### Initialize the agent\n",
    "\n",
    "Initialize the agent with the configured tools, `writer_model`, and a system prompt that defines the agent’s role, tone, output format, and how it should use tools.\n",
    "\n",
    "> **Best practice:** Use a clear and specific system prompt to define your agent’s role and expected behavior. If you include tools, be explicit about when and how the agent should use them. For many use cases, a single agent with one model is sufficient and keeps the architecture simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bf697-e9ce-4ae4-9b80-0e6e06809460",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful enterprise assistant. Use your knowledge and available tools (if provided)\n",
    "to answer user queries accurately and helpfully.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    model=writer_model,\n",
    "    tools=tools,         # or [] if no tools\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076baac-b1f2-4c64-a236-55a3725f619c",
   "metadata": {},
   "source": [
    "### Run the agent\n",
    "\n",
    "Once you’ve finished importing and initializing the WRITER provider in Strands Agents, you can ask the agent a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f08c96-5db6-4c4a-9358-522e887f7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent(\"What is 2+2\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2027947-8aab-4bde-8588-d9daae9120a1",
   "metadata": {},
   "source": [
    "## Example: advanced multi-agent research and content creation\n",
    "\n",
    "This code provides an **extended example** of a multi-agent workflow \n",
    "using the Strands SDK. It goes beyond a basic demonstration to showcase a more \n",
    "detailed, real-world application scenario involving multiple specialized agents:\n",
    "\n",
    "1. **Research Agent**: Leveraging `palmyra-x5` to perform comprehensive web-based research, \n",
    "   gather verified information, and summarize insights.\n",
    "\n",
    "2. **Content Agent**: Utilizing `palmyra-creative` to craft engaging, platform-optimized \n",
    "   social media content based on the research findings.\n",
    "\n",
    "This extended example covers:\n",
    "\n",
    "- Importing and configuring necessary modules  \n",
    "- Initializing and customizing models for each agent  \n",
    "- Creating agents with specialized roles and workflows  \n",
    "- Orchestrating a multi-step pipeline for research and content creation  \n",
    "- Passing intermediate outputs between agents in a multi-step workflow\n",
    "\n",
    "## Setup\n",
    "Import the required modules to define agents, configure WRITER models, and enable tool-based HTTP requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c30ed5-778b-4679-afdf-a3dbb0bbf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import Agent\n",
    "from strands.models.writer import WriterModel\n",
    "from strands_tools import http_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420bf176-acd0-4ce6-8506-171ca9968bcd",
   "metadata": {},
   "source": [
    "## Initialize the models\n",
    "\n",
    "- `palmyra-creative` → for creative social content.\n",
    "- `palmyra-x5` → for accurate research and factual lookups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42689c-ef32-4685-81e2-e21f08d4faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the creative content model\n",
    "content_model = WriterModel(\n",
    "    model_id=\"palmyra-creative\",\n",
    ")\n",
    "\n",
    "# Initialize the research model\n",
    "research_model = WriterModel(\n",
    "    model_id=\"palmyra-x5\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f0acd-82d3-4584-bdfc-9281f55fb7d7",
   "metadata": {},
   "source": [
    "## Define system prompts\n",
    "\n",
    "- **Research agent prompt:** instructs the agent to gather and summarize factual information for a given topic.\n",
    "- **X Post assistant prompt:** guides the agent to create an engaging social post tailored specifically for X/Twitter.\n",
    "- **LinkedIn Post assistant prompt:** guides the agent to write a professional, value‑focused LinkedIn post.\n",
    "- **Creative assistant prompt:** instructs the agent to produce flexible social content that can be adapted across platforms.\n",
    "- **Style assistant prompt:** instructs the agent to rewrite existing content in a specified tone or style (e.g., professional, concise).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "443e6f5f-50a1-40a6-9479-2908076d42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_ASSISTANT_PROMPT = \"\"\"\n",
    "You are the Research Assistant. Gather accurate factual information on the topic\n",
    "provided and return a clear, structured summary of key findings, insights, and\n",
    "important points relevant to the query.\n",
    "\"\"\"\n",
    "\n",
    "X_POST_ASSISTANT_PROMPT = \"\"\"\n",
    "You are the X Post Assistant. Using the input summary or topic, generate\n",
    "short, engaging posts tailored specifically for X (Twitter). Focus on strong\n",
    "hooks, concise language, and shareable insights in fewer than 280 characters.\n",
    "\"\"\"\n",
    "\n",
    "LINKEDIN_POST_ASSISTANT_PROMPT = \"\"\"\n",
    "You are the LinkedIn Post Assistant. Using the input summary or topic,\n",
    "create a professional, value‑focused LinkedIn post. Include key takeaways,\n",
    "industry relevance, and a call to engagement or reflection.\n",
    "\"\"\"\n",
    "\n",
    "CREATIVE_ASSISTANT_PROMPT = \"\"\"\n",
    "You are the Creative Content Assistant. Your job is to produce versatile\n",
    "social content that may be repurposed for different platforms. Blend\n",
    "original messaging with existing insights while maintaining clarity and tone.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd6abf-f9bc-403b-9ce6-a7e936bef09b",
   "metadata": {},
   "source": [
    "## Create agents\n",
    "\n",
    "- **Research Agent** gathers and summarizes factual information about a topic using a Palmyra‑X5 model. It does *not* include live HTTP or web lookup tools in this example, but focuses on internal knowledge and reasoning.\n",
    "\n",
    "- **X Post Assistant** generates short, engaging social posts optimized for X (formerly Twitter), using the Palmyra‑Creative model.\n",
    "\n",
    "- **LinkedIn Post Assistant** produces value‑focused, professional content tailored specifically for LinkedIn, using the Palmyra‑Creative model.\n",
    "\n",
    "- **Creative Assistant** provides versatile social content that can be adapted or repurposed across platforms when a general creative response is needed.\n",
    "\n",
    "- **Style Assistant** (optional) restyles existing content into a requested tone or format (e.g., professional, concise, humorous).\n",
    "\n",
    "All of these are defined as **tool‑wrapped agents** that the main orchestrator can call dynamically to satisfy different user needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e3c6ce2-ac01-402d-bf61-a016529caa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import tool\n",
    "\n",
    "@tool\n",
    "def research_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Research specialist: gathers and summarizes factual information for the topic.\n",
    "\n",
    "    Args:\n",
    "        query: The topic or question to research.\n",
    "    Returns:\n",
    "        A factual summary as text.\n",
    "    \"\"\"\n",
    "    research_model = WriterModel(model_id=\"palmyra-x5\")\n",
    "    agent = Agent(\n",
    "        model=research_model,\n",
    "        system_prompt=RESEARCH_ASSISTANT_PROMPT,\n",
    "        callback_handler=None,\n",
    "    )\n",
    "    return str(agent(query))\n",
    "\n",
    "\n",
    "@tool\n",
    "def x_post_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    X Post specialist: crafts posts optimized for X (Twitter).\n",
    "\n",
    "    Args:\n",
    "        query: Summary or topic for the X post.\n",
    "    Returns:\n",
    "        A short, engaging X post.\n",
    "    \"\"\"\n",
    "    x_model = WriterModel(model_id=\"palmyra-creative\")\n",
    "    agent = Agent(\n",
    "        model=x_model,\n",
    "        system_prompt=X_POST_ASSISTANT_PROMPT,\n",
    "        callback_handler=None,\n",
    "    )\n",
    "    return str(agent(query))\n",
    "\n",
    "\n",
    "@tool\n",
    "def linkedin_post_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    LinkedIn Post specialist: produces professional posts for LinkedIn.\n",
    "\n",
    "    Args:\n",
    "        query: Summary or topic for the LinkedIn post.\n",
    "    Returns:\n",
    "        A LinkedIn‑optimized post.\n",
    "    \"\"\"\n",
    "    li_model = WriterModel(model_id=\"palmyra-creative\")\n",
    "    agent = Agent(\n",
    "        model=li_model,\n",
    "        system_prompt=LINKEDIN_POST_ASSISTANT_PROMPT,\n",
    "        callback_handler=None,\n",
    "    )\n",
    "    return str(agent(query))\n",
    "\n",
    "\n",
    "@tool\n",
    "def creative_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Creative content specialist: generates flexible social content\n",
    "    that can be adapted or repurposed for any platform.\n",
    "\n",
    "    Args:\n",
    "        query: Topic or research summary\n",
    "    Returns:\n",
    "        Versatile social media copy.\n",
    "    \"\"\"\n",
    "    creative_model = WriterModel(model_id=\"palmyra-creative\")\n",
    "    agent = Agent(\n",
    "        model=creative_model,\n",
    "        system_prompt=CREATIVE_ASSISTANT_PROMPT,\n",
    "        callback_handler=None,\n",
    "    )\n",
    "    return str(agent(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d6666-d00f-42f3-9a7c-7110555fb2b1",
   "metadata": {},
   "source": [
    "## Orchestrator Agent\n",
    "\n",
    "This example uses a central **Orchestrator Agent** that coordinates multiple specialist agents, each wrapped as a tool. The orchestrator examines the user’s request and dynamically delegates subtasks to the appropriate assistant tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222a8725-796e-46cd-a566-32807ed4028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_agent_orchestrator = Agent(\n",
    "    model=WriterModel(model_id=\"palmyra-x5\"),\n",
    "    system_prompt=\"\"\"\n",
    "You are the Orchestrator Agent. Decide whether to:\n",
    "- call research_assistant(query) for facts,\n",
    "- call x_post_assistant(summary) to generate an X post,\n",
    "- call linkedin_post_assistant(summary) to generate a LinkedIn post,\n",
    "- call creative_assistant(summary) for general creative social content.\n",
    "\n",
    "Use tools explicitly and embed their results in your response.\n",
    "\"\"\",\n",
    "    callback_handler=None,\n",
    "    tools=[\n",
    "        research_assistant,\n",
    "        x_post_assistant,\n",
    "        linkedin_post_assistant,\n",
    "        creative_assistant,\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d773414-538a-4402-88bc-2d0211f2d17d",
   "metadata": {},
   "source": [
    "## Run the workflow\n",
    "\n",
    "Call the orchestrator to research a topic and produce both an X/Twitter post and a LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de872fcb-6d23-49c5-ab57-711edc9379de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results of your requests:\n",
      "\n",
      "**X Post:**\n",
      "\"Sustainable fashion is on the rise! From circular business models to eco-friendly materials and second-hand shopping, consumers are driving change. Let's make fashion more sustainable! #SustainableFashion #EcoFriendly\"\n",
      "\n",
      "**LinkedIn Post:**\n",
      "\"The fashion industry is shifting towards sustainability, driven by consumer demand and technological innovation. Discover the key trends and opportunities in sustainable fashion.\n",
      "\n",
      "The industry is adopting circular economy models, innovative materials, and ethical production practices. While there are challenges to overcome, the opportunities for growth and positive change are significant.\n",
      "\n",
      "Some of the key trends include the use of eco-friendly materials, clothing rental services, and digital printing and 3D design technologies. Consumers are driving demand for sustainable fashion, and brands are responding by prioritizing transparency and sustainability.\n",
      "\n",
      "As the industry continues to evolve, it's essential to consider the challenges and opportunities that lie ahead. By working together, we can create a more sustainable future for fashion.\n",
      "\n",
      "#SustainableFashion #FashionIndustry\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = multi_agent_orchestrator(\n",
    "    \"Research sustainable fashion trends and produce both an X post and a LinkedIn post.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8e189-7854-47c0-8e36-449768ab8be0",
   "metadata": {},
   "source": [
    "Research the topic and generate a concise, engaging post optimized for X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d566ff-0fb1-464e-afaa-f4aa00395837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an engaging X post about the latest trends in electric vehicles:\n",
      "\"Electric vehicles are taking over the roads! With advancements in battery tech and expanded charging infrastructure, the future is electric! Share your favorite EV model and let's discuss the future of transportation! #ElectricVehicles #SustainableTransport\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = multi_agent_orchestrator(\n",
    "    \"Research electric vehicles and create an engaging X post about the latest trends.\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c05c5-8a79-4ebc-a23a-6ee7da9f526b",
   "metadata": {},
   "source": [
    "Research the topic and produce a professional, insight‑driven LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "115d6530-6a95-4fb8-9647-3a8da3a3aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a professional LinkedIn post on remote work productivity:\n",
      "\n",
      "\"Boost your remote work productivity with these proven strategies and tools. From creating a conducive work environment to leveraging technology, discover how to stay focused, motivated, and connected while working remotely.\n",
      "\n",
      "To optimize your remote work experience, consider the following:\n",
      "\n",
      "* Create a dedicated workspace that is quiet, comfortable, and free from distractions\n",
      "* Establish a structured schedule with regular working hours and breaks\n",
      "* Minimize digital distractions and use tools like website blockers to stay on track\n",
      "* Enhance communication and collaboration with your team through video conferencing and collaboration software\n",
      "* Prioritize self-care and maintain a healthy work-life balance\n",
      "\n",
      "Some popular productivity tools for remote workers include project management tools like Trello and Asana, time tracking tools like Toggl and Harvest, and communication tools like Slack and Zoom.\n",
      "\n",
      "By implementing these strategies and utilizing the right tools, you can maintain high levels of productivity, stay connected with your team, and achieve a better work-life balance.\n",
      "\n",
      "#RemoteWork #ProductivityTips\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = multi_agent_orchestrator(\n",
    "    \"Research remote work productivity and craft a professional LinkedIn post.\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bbde6-bb73-4570-a0ff-c21403f3d2e0",
   "metadata": {},
   "source": [
    "## Using Strands with Amazon Bedrock\n",
    "\n",
    "In addition to direct WRITER API integration, Strands also supports running WRITER models through **Amazon Bedrock**.\n",
    "\n",
    "This is useful when you need:\n",
    "- Centralized model access and governance through AWS\n",
    "- Alignment with existing Bedrock-based infrastructure\n",
    "- Standardized IAM-based authentication and auditing\n",
    "\n",
    "When using Amazon Bedrock, the Strands agent architecture remains the same. The primary difference is the **model backend configuration**, which points to Bedrock-hosted WRITER models instead of the direct WRITER API.\n",
    "\n",
    "\n",
    "### Bedrock Model Configuration\n",
    "\n",
    "Instead of using `WriterModel`, use `BedrockModel` from Strands.\n",
    "\n",
    "The following client configuration uses the `us.writer.palmyra-x5-v1:0` model ID.\n",
    "\n",
    "Before selecting an inference profile, verify which AWS Regions currently support Writer models and ensure the chosen profile is enabled in your AWS account.\n",
    "\n",
    "For credential configuration, Strands relies on the standard AWS credential resolution chain. Make sure your environment is configured with valid AWS credentials (for example, via environment variables, shared credentials files, or IAM roles) as described in the Strands [documentation](https://strandsagents.com/latest/documentation/docs/user-guide/quickstart/#configuring-credentials)\n",
    "\n",
    "Additional details on enabling and using Writer models on Amazon Bedrock—including model availability, permissions, and setup—are covered in the Writer Bedrock integration [guide](https://dev.writer.com/home/integrations/bedrock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e90778-efb4-42f8-b1b3-02a6e243806c",
   "metadata": {},
   "source": [
    "Next, configure your AWS credentials for Amazon Bedrock access. It is recommended to set these values using standard AWS credential mechanisms (such as a `.env` file, shared credentials file, or IAM role). However, for demonstration purposes, this tutorial sets the credentials directly as environment variables if they are not already defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6d65cb1-cd4e-414a-9f2b-15f41082e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your AWS_ACCESS_KEY_ID:  ········\n",
      "Enter your AWS_SECRET_ACCESS_KEY:  ········\n",
      "Enter your AWS_SESSION_TOKEN:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"AWS_ACCESS_KEY_ID\"):\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass.getpass(\"Enter your AWS_ACCESS_KEY_ID: \")\n",
    "\n",
    "if not os.getenv(\"AWS_SECRET_ACCESS_KEY\"):\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass.getpass(\"Enter your AWS_SECRET_ACCESS_KEY: \")\n",
    "\n",
    "if not os.getenv(\"AWS_SESSION_TOKEN\"):\n",
    "    os.environ[\"AWS_SESSION_TOKEN\"] = getpass.getpass(\"Enter your AWS_SESSION_TOKEN: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b68cc-2222-4e89-90c1-f9b613458b89",
   "metadata": {},
   "source": [
    "### Common Bedrock configuration parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|----------|-------------|\n",
    "| `model_id` | The Amazon Bedrock model identifier (for example, a WRITER Palmyra inference profile). |\n",
    "| `temperature` | Controls response randomness; higher values produce more varied outputs. |\n",
    "| `max_tokens` | Maximum number of tokens the model can generate in a single response. |\n",
    "| `streaming` | Enables or disables streaming responses from the model. |\n",
    "| `guardrail_id` | Identifier of the Amazon Bedrock guardrail to apply to model outputs. |\n",
    "| `cache_prompt` | Enables caching of prompts to improve performance and reduce repeated computation. |\n",
    "| `cache_tools` | Enables caching of tool definitions and usage for repeated requests. |\n",
    "| `boto_session` | Custom `boto3` session used to control AWS credentials and configuration. |\n",
    "| `additional_request_fields` | Additional model-specific parameters passed directly to the Bedrock request. |\n",
    "\n",
    "<div style=\"\n",
    "  border: 1px solid rgba(245, 158, 11, 0.2);\n",
    "  background-color: rgba(245, 158, 11, 0.08);\n",
    "  color: rgb(146, 64, 14);\n",
    "  padding: 16px 20px;\n",
    "  border-radius: 12px;\n",
    "  margin: 16px 0;\n",
    "\">\n",
    "\n",
    "<strong>Region resolution note</strong><br/>\n",
    "When using Amazon Bedrock, the AWS region is resolved using boto3’s standard priority order.\n",
    "If you experience unexpected region behavior, check your AWS configuration files and consider\n",
    "explicitly setting <code>region_name</code> on the <code>BedrockModel</code>.\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "The example below shows how to configure a Strands agent to use a WRITER model hosted on Amazon Bedrock, using the `us.writer.palmyra-x5-v1:0` cross-region inference profile for Palmyra X5.  \n",
    "Make sure the model is enabled in your AWS account and supported in your selected AWS Region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b1a400-5d27-4a24-b76b-370deb8abd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great question! Using Amazon Bedrock together with Strands creates a powerful combo for building and managing AI workflows—especially when you're aiming for both flexibility and enterprise-grade control.\n",
      "\n",
      "Amazon Bedrock gives you serverless access to a range of top foundation models (FMs) from AWS and third-party providers like Anthropic, Meta, and Mistral. That means you can experiment with and deploy large language models without managing infrastructure—perfect for rapid prototyping and scaling.\n",
      "\n",
      "Strands, on the other hand, is all about orchestration and governance. It helps you design, monitor, and manage complex AI workflows—chaining prompts, models, and tools—while adding visibility, versioning, and compliance controls. Think of it as a workflow engine tailored for LLM operations.\n",
      "\n",
      "Together, they let you:\n",
      "- Quickly swap and test models via Bedrock while using Strands to manage which model serves which use case.\n",
      "- Enforce security, audit trails, and approval workflows across AI pipelines.\n",
      "- Standardize prompt engineering practices and scale them across teams.\n",
      "- Monitor performance, cost, and drift across your AI applications.\n",
      "\n",
      "It’s a clean separation: Bedrock handles the “brainpower,” Strands handles the “workflow intelligence.”\n",
      "\n",
      "Are you building a specific type of AI application—like customer support automation or document processing? I’d love to tailor how this combo could work for your use case.Great question! Using Amazon Bedrock together with Strands creates a powerful combo for building and managing AI workflows—especially when you're aiming for both flexibility and enterprise-grade control.\n",
      "\n",
      "Amazon Bedrock gives you serverless access to a range of top foundation models (FMs) from AWS and third-party providers like Anthropic, Meta, and Mistral. That means you can experiment with and deploy large language models without managing infrastructure—perfect for rapid prototyping and scaling.\n",
      "\n",
      "Strands, on the other hand, is all about orchestration and governance. It helps you design, monitor, and manage complex AI workflows—chaining prompts, models, and tools—while adding visibility, versioning, and compliance controls. Think of it as a workflow engine tailored for LLM operations.\n",
      "\n",
      "Together, they let you:\n",
      "- Quickly swap and test models via Bedrock while using Strands to manage which model serves which use case.\n",
      "- Enforce security, audit trails, and approval workflows across AI pipelines.\n",
      "- Standardize prompt engineering practices and scale them across teams.\n",
      "- Monitor performance, cost, and drift across your AI applications.\n",
      "\n",
      "It’s a clean separation: Bedrock handles the “brainpower,” Strands handles the “workflow intelligence.”\n",
      "\n",
      "Are you building a specific type of AI application—like customer support automation or document processing? I’d love to tailor how this combo could work for your use case.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from strands import Agent\n",
    "from strands.models.bedrock import BedrockModel\n",
    "from strands_tools import calculator\n",
    "\n",
    "# Configure Amazon Bedrock model with Palmyra model ID\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.writer.palmyra-x5-v1:0\",\n",
    "    region_name=\"us-west-2\",  # AWS region where the Bedrock model is enabled\n",
    ")\n",
    "\n",
    "agent = Agent(model=bedrock_model)\n",
    "response = agent(\"Explain the benefits of using Bedrock + Strands for AI workflows.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0d131-b95d-419e-9b00-7c8993b01603",
   "metadata": {},
   "source": [
    "## Example: Writer MCP + Strands agents   \n",
    "\n",
    "This recipe demonstrates how to combine:\n",
    "\n",
    "- **Writer MCP Server** (via `writer-sdk-mcp`)\n",
    "- **Strands Agents**\n",
    "- **WriterModel (Palmyra-x5)**\n",
    "- **MCP Tools over stdio**\n",
    "\n",
    "to orchestrate multi-step research and content generation workflows.\n",
    "\n",
    "\n",
    "## Install dependencies\n",
    "\n",
    "Install Strands (with Writer support) and the Strands Agent Tools package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff2142-c863-47fd-acfa-25a5dd43700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'strands-agents[writer]' strands-agents-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cff5a4-8b6d-4808-8358-cc21333e6c14",
   "metadata": {},
   "source": [
    "## Building a custom MCP client with Strands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e779a8a-5c02-43ba-8a77-049c42dca932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from strands import Agent\n",
    "from strands.models.writer import WriterModel\n",
    "from strands.tools.mcp import MCPClient\n",
    "from mcp import stdio_client, StdioServerParameters\n",
    "\n",
    "\n",
    "\n",
    "def log_server_init_and_requests(client_factory):\n",
    "    \"\"\"Wrap an MCP client to log server start and requests.\"\"\"\n",
    "    class LoggingMCPClient:\n",
    "        def __init__(self):\n",
    "            self._client = client_factory()\n",
    "\n",
    "        def __enter__(self):\n",
    "            print(\"[LOG] Starting MCP server...\")\n",
    "            self._client.__enter__()\n",
    "            print(\"[LOG] MCP server started.\")\n",
    "            return self\n",
    "\n",
    "        def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "            self._client.__exit__(exc_type, exc_val, exc_tb)\n",
    "\n",
    "        def __getattr__(self, name):\n",
    "            orig_attr = getattr(self._client, name)\n",
    "            if callable(orig_attr):\n",
    "                def hooked(*args, **kwargs):\n",
    "                    print(f\"[LOG] MCP request: {name}, args={args}, kwargs={kwargs}\")\n",
    "                    result = orig_attr(*args, **kwargs)\n",
    "                    print(f\"[LOG] MCP Server starting with tools: {',*\\n'.join([el.tool_name for el in result])}\")\n",
    "                    return result\n",
    "                return hooked\n",
    "            return orig_attr\n",
    "    return LoggingMCPClient()\n",
    "\n",
    "\n",
    "# Connect to the Writer MCP server via stdio\n",
    "writer_mcp_client = log_server_init_and_requests(lambda: MCPClient(lambda: stdio_client(\n",
    "    StdioServerParameters(\n",
    "        command=\"npx\",\n",
    "        args=[\"-y\", \"writer-sdk-mcp@latest\"],\n",
    "        env={\"WRITER_API_KEY\": os.environ[\"WRITER_API_KEY\"]}\n",
    "    )\n",
    ")))\n",
    "\n",
    "def content_workflow_client(user_request: str):\n",
    "    \"\"\"\n",
    "    Custom MCP client that orchestrates complex content workflows\n",
    "    using Writer MCP tools.\n",
    "    \"\"\"\n",
    "    with writer_mcp_client:\n",
    "        tools = writer_mcp_client.list_tools_sync()\n",
    "        agent = Agent(\n",
    "            model=writer_model,\n",
    "            tools=tools,\n",
    "            system_prompt=\"\"\"You are a content workflow assistant that can:\n",
    "            - Upload and analyze files\n",
    "            - Generate content using Writer's models\n",
    "            - Query Knowledge Graphs for research\n",
    "            - Perform real-time web research for up-to-date, factual, or time-sensitive information using web_search_tools\n",
    "            - Analyze images and extract insights\n",
    "            - Chain multiple operations together seamlessly\n",
    "            Use the available Writer MCP tools to fulfill user requests efficiently.\"\"\"\n",
    "        )\n",
    "        return agent(user_request)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0ec38-d230-45bb-b3f5-ed183c53db0f",
   "metadata": {},
   "source": [
    "## Example workflow request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3552830a-221e-4960-b1af-9395307ae997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Starting MCP server...\n",
      "[LOG] MCP server started.\n",
      "[LOG] MCP request: list_tools_sync, args=(), kwargs={}\n",
      "[LOG] MCP Server starting with tools: retrieve_applications,*\n",
      "list_applications,*\n",
      "generate_content_applications,*\n",
      "create_applications_jobs,*\n",
      "retrieve_applications_jobs,*\n",
      "list_applications_jobs,*\n",
      "retry_applications_jobs,*\n",
      "update_applications_graphs,*\n",
      "list_applications_graphs,*\n",
      "chat_chat,*\n",
      "create_completions,*\n",
      "list_models,*\n",
      "create_graphs,*\n",
      "retrieve_graphs,*\n",
      "update_graphs,*\n",
      "list_graphs,*\n",
      "delete_graphs,*\n",
      "add_file_to_graph_graphs,*\n",
      "question_graphs,*\n",
      "remove_file_from_graph_graphs,*\n",
      "retrieve_files,*\n",
      "list_files,*\n",
      "delete_files,*\n",
      "download_files,*\n",
      "retry_files,*\n",
      "upload_files,*\n",
      "ai_detect_tools,*\n",
      "context_aware_splitting_tools,*\n",
      "parse_pdf_tools,*\n",
      "web_search_tools,*\n",
      "medical_tools_comprehend,*\n",
      "translate_translation,*\n",
      "analyze_vision,*\n",
      "search_docs\n",
      "To create content about sustainable fashion trends, including a blog post outline and social media content ideas, we can break down the task into several steps. \n",
      "\n",
      "1. **Research Sustainable Fashion Trends:**\n",
      "   - Use the `web_search_tools` function to search for the latest sustainable fashion trends.\n",
      "\n",
      "2. **Create a Blog Post Outline:**\n",
      "   - Based on the research findings, generate a blog post outline using the `generate_content_applications` or `create_completions` function.\n",
      "\n",
      "3. **Develop Social Media Content Ideas:**\n",
      "   - Use the research findings to generate social media content ideas.\n",
      "\n",
      "Let's begin with researching sustainable fashion trends.\n",
      "\n",
      "\n",
      "Tool #1: web_search_tools\n",
      "The latest sustainable fashion trends include circular fashion, upcycled clothing, clothing rental, recycled materials, eco-friendly fabrics and dyes, on-demand production, slow fashion, e-textiles, virtual try-ons, AI fashion tools, and transparent supply chains.\n",
      "\n",
      "Now, let's create a blog post outline on sustainable fashion trends using the `create_completions` function.\n",
      "\n",
      "\n",
      "Tool #2: create_completions\n",
      "Here's a suggested outline for a blog post on the latest sustainable fashion trends:\n",
      "\n",
      "**Title:** \"Revolutionizing Fashion: The Top Sustainable Trends to Watch\"\n",
      "\n",
      "**I. Introduction**\n",
      "* Briefly introduce the importance of sustainability in the fashion industry\n",
      "* Mention the growing awareness and demand for eco-friendly fashion practices\n",
      "* Preview the sustainable fashion trends that will be covered in the post\n",
      "\n",
      "**II. Circular Fashion and Upcycled Clothing**\n",
      "* Define circular fashion and its significance in reducing waste\n",
      "* Discuss the concept of upcycled clothing and its creative possibilities\n",
      "* Provide examples of brands or designers incorporating upcycled materials into their designs\n",
      "\n",
      "**III. Clothing Rental and Sharing**\n",
      "* Explain the benefits of clothing rental services for reducing waste and promoting sustainability\n",
      "* Discuss the rise of clothing sharing platforms and their impact on the industry\n",
      "* Highlight examples of successful clothing rental businesses or peer-to-peer sharing platforms\n",
      "\n",
      "**IV. Recycled Materials and Eco-Friendly Fabrics**\n",
      "* Discuss the use of recycled materials in fashion, such as recycled polyester or nylon\n",
      "* Introduce eco-friendly fabrics like organic cotton, hemp, and Tencel\n",
      "* Explore the benefits of using these materials, including reduced environmental impact and improved durability\n",
      "\n",
      "**V. Sustainable Dyes and On-Demand Production**\n",
      "* Discuss the environmental impact of traditional dyeing processes and the benefits of sustainable dyeing methods\n",
      "* Explain the concept of on-demand production and its potential to reduce waste and excess inventory\n",
      "* Provide examples of brands using on-demand production or sustainable dyeing practices\n",
      "\n",
      "**VI. Slow Fashion and Mindful Consumption**\n",
      "* Define slow fashion and its emphasis on quality, durability, and timeless design\n",
      "* Discuss the benefits of adopting a slow fashion mindset, including reduced waste and a more thoughtful approach to consumption\n",
      "* Encourage readers to adopt slow fashion practices in their own lives\n",
      "\n",
      "**VII. E-Textiles and Innovative Materials**\n",
      "* Introduce the concept of e-textiles and their potential applications in fashion\n",
      "* Discuss innovative materials like plant-based fabrics, mushroom-based materials, or recycled textiles\n",
      "* Explore the possibilities and challenges associated with these emerging materials\n",
      "\n",
      "**VIII. Virtual Try-Ons and AI Fashion Tools**\n",
      "* Discuss the role of virtual try-ons and AI-powered fashion tools in reducing returns and waste\n",
      "* Explain how these technologies can enhance the shopping experience and promote sustainability\n",
      "* Highlight examples of brands or startups using virtual try-ons or AI fashion tools\n",
      "\n",
      "**IX. Transparent Supply Chains**\n",
      "* Discuss the importance of transparency in supply chains for promoting sustainability and accountability\n",
      "* Explain how brands can implement transparent supply chains, including sourcing materials responsibly and ensuring fair labor practices\n",
      "* Provide examples of brands prioritizing transparency in their supply chains\n",
      "\n",
      "**X. Conclusion**\n",
      "* Recap the sustainable fashion trends covered in the post\n",
      "* Emphasize the importance of adopting sustainable practices in the fashion industry\n",
      "* Encourage readers to explore and support sustainable fashion brands and practices.\n",
      "\n",
      "To develop social media content ideas, let's analyze the research findings and identify key points that can be used to create engaging content.\n",
      "\n",
      "Some social media content ideas based on the sustainable fashion trends include:\n",
      "\n",
      "* Share infographics highlighting the benefits of circular fashion, upcycled clothing, and clothing rental services.\n",
      "* Create a video showcasing eco-friendly fabrics and dyes, featuring interviews with sustainable fashion experts or brand representatives.\n",
      "* Host a social media contest encouraging followers to share their own slow fashion practices or favorite sustainable fashion brands.\n",
      "* Collaborate with influencers or bloggers to showcase innovative materials like e-textiles or plant-based fabrics.\n",
      "* Share behind-the-scenes content highlighting brands' efforts to implement transparent supply chains.\n",
      "\n",
      "Would you like me to suggest more social media content ideas or provide guidance on creating engaging content around sustainable fashion trends?Research & Content: Here's a suggested outline for a blog post on the latest sustainable fashion trends:\n",
      "\n",
      "**Title:** \"Revolutionizing Fashion: The Top Sustainable Trends to Watch\"\n",
      "\n",
      "**I. Introduction**\n",
      "* Briefly introduce the importance of sustainability in the fashion industry\n",
      "* Mention the growing awareness and demand for eco-friendly fashion practices\n",
      "* Preview the sustainable fashion trends that will be covered in the post\n",
      "\n",
      "**II. Circular Fashion and Upcycled Clothing**\n",
      "* Define circular fashion and its significance in reducing waste\n",
      "* Discuss the concept of upcycled clothing and its creative possibilities\n",
      "* Provide examples of brands or designers incorporating upcycled materials into their designs\n",
      "\n",
      "**III. Clothing Rental and Sharing**\n",
      "* Explain the benefits of clothing rental services for reducing waste and promoting sustainability\n",
      "* Discuss the rise of clothing sharing platforms and their impact on the industry\n",
      "* Highlight examples of successful clothing rental businesses or peer-to-peer sharing platforms\n",
      "\n",
      "**IV. Recycled Materials and Eco-Friendly Fabrics**\n",
      "* Discuss the use of recycled materials in fashion, such as recycled polyester or nylon\n",
      "* Introduce eco-friendly fabrics like organic cotton, hemp, and Tencel\n",
      "* Explore the benefits of using these materials, including reduced environmental impact and improved durability\n",
      "\n",
      "**V. Sustainable Dyes and On-Demand Production**\n",
      "* Discuss the environmental impact of traditional dyeing processes and the benefits of sustainable dyeing methods\n",
      "* Explain the concept of on-demand production and its potential to reduce waste and excess inventory\n",
      "* Provide examples of brands using on-demand production or sustainable dyeing practices\n",
      "\n",
      "**VI. Slow Fashion and Mindful Consumption**\n",
      "* Define slow fashion and its emphasis on quality, durability, and timeless design\n",
      "* Discuss the benefits of adopting a slow fashion mindset, including reduced waste and a more thoughtful approach to consumption\n",
      "* Encourage readers to adopt slow fashion practices in their own lives\n",
      "\n",
      "**VII. E-Textiles and Innovative Materials**\n",
      "* Introduce the concept of e-textiles and their potential applications in fashion\n",
      "* Discuss innovative materials like plant-based fabrics, mushroom-based materials, or recycled textiles\n",
      "* Explore the possibilities and challenges associated with these emerging materials\n",
      "\n",
      "**VIII. Virtual Try-Ons and AI Fashion Tools**\n",
      "* Discuss the role of virtual try-ons and AI-powered fashion tools in reducing returns and waste\n",
      "* Explain how these technologies can enhance the shopping experience and promote sustainability\n",
      "* Highlight examples of brands or startups using virtual try-ons or AI fashion tools\n",
      "\n",
      "**IX. Transparent Supply Chains**\n",
      "* Discuss the importance of transparency in supply chains for promoting sustainability and accountability\n",
      "* Explain how brands can implement transparent supply chains, including sourcing materials responsibly and ensuring fair labor practices\n",
      "* Provide examples of brands prioritizing transparency in their supply chains\n",
      "\n",
      "**X. Conclusion**\n",
      "* Recap the sustainable fashion trends covered in the post\n",
      "* Emphasize the importance of adopting sustainable practices in the fashion industry\n",
      "* Encourage readers to explore and support sustainable fashion brands and practices.\n",
      "\n",
      "To develop social media content ideas, let's analyze the research findings and identify key points that can be used to create engaging content.\n",
      "\n",
      "Some social media content ideas based on the sustainable fashion trends include:\n",
      "\n",
      "* Share infographics highlighting the benefits of circular fashion, upcycled clothing, and clothing rental services.\n",
      "* Create a video showcasing eco-friendly fabrics and dyes, featuring interviews with sustainable fashion experts or brand representatives.\n",
      "* Host a social media contest encouraging followers to share their own slow fashion practices or favorite sustainable fashion brands.\n",
      "* Collaborate with influencers or bloggers to showcase innovative materials like e-textiles or plant-based fabrics.\n",
      "* Share behind-the-scenes content highlighting brands' efforts to implement transparent supply chains.\n",
      "\n",
      "Would you like me to suggest more social media content ideas or provide guidance on creating engaging content around sustainable fashion trends?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = content_workflow_client(\n",
    "    \"Research and create content about sustainable fashion trends, \"\n",
    "    \"including a blog post outline and social media content ideas.\"\n",
    ")\n",
    "\n",
    "print(\"Research & Content:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
