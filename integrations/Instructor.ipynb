{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tutorial_intro",
   "metadata": {},
   "source": [
    "# Structured output with Instructor\n",
    "\n",
    "This tutorial demonstrates how to use [Instructor](https://useinstructor.com/) with Writer to extract structured data like JSON from text, CSV, or PDF files.\n",
    "\n",
    "You'll learn how to define Pydantic models, set up the Writer client, extract structured data, and generate CSV outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before getting started, you'll need:\n",
    "\n",
    "- A [Writer AI Studio](https://app.writer.com/register) account\n",
    "- An API key, which you can obtain by following the [API Quickstart](https://dev.writer.com/api-guides/quickstart)\n",
    "\n",
    "## Setup\n",
    "Install the next libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_dependencies",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"instructor[writer]\" writer-sdk python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_setup",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "Set the `WRITER_API_KEY` environment variable. You can store it in a `.env` file or enter it interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_var",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Writer API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from writerai import Writer\n",
    "\n",
    "if not os.getenv(\"WRITER_API_KEY\"):\n",
    "    os.environ[\"WRITER_API_KEY\"] = getpass.getpass(\"Enter your Writer API key: \")\n",
    "\n",
    "writer_client = Writer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic_usage_intro",
   "metadata": {},
   "source": [
    "## Basic usage with Instructor\n",
    "\n",
    "Here's a minimal example using Instructor to extract structured data from a simple string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic_usage_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John' age=30\n"
     ]
    }
   ],
   "source": [
    "import instructor\n",
    "from writerai import Writer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Initialize Instructor client\n",
    "client = instructor.from_writer(Writer(api_key=os.getenv('WRITER_API_KEY')))\n",
    "\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "user = client.chat.completions.create(\n",
    "    model=\"palmyra-x5\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 30 years old\"}],\n",
    "    response_model=User,\n",
    ")\n",
    "\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_model_intro",
   "metadata": {},
   "source": [
    "## Defining a data model for file extraction\n",
    "\n",
    "You can define a Pydantic model to validate structured data extracted from text, CSV, or PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pydantic_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from pydantic import BaseModel, AfterValidator, Field\n",
    "\n",
    "class UserExtract(BaseModel):\n",
    "    @staticmethod\n",
    "    def first_last_name_validator(v):\n",
    "        if v[0] != v[0].upper() or v[1:] != v[1:].lower() or not v.isalpha():\n",
    "            raise ValueError(\"Name must contain only letters and start with uppercase letter\")\n",
    "        return v\n",
    "\n",
    "    first_name: Annotated[str, AfterValidator(first_last_name_validator)] = Field(..., description=\"The first name\")\n",
    "    last_name: Annotated[str, AfterValidator(first_last_name_validator)] = Field(..., description=\"The last name\")\n",
    "    email: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file_parsing_intro",
   "metadata": {},
   "source": [
    "## File processing functions\n",
    "\n",
    "Define functions to read text, CSV, or PDF files and extract content for structured parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "file_processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Type, List, Iterable\n",
    "import csv\n",
    "import json\n",
    "from writerai import AsyncWriter\n",
    "\n",
    "async_writer_client = AsyncWriter()\n",
    "\n",
    "\n",
    "async def fetch_file_text(file_path: str, name: str, extension: str) -> str:\n",
    "    allowed_extensions = [\".txt\", \".csv\", \".pdf\"]\n",
    "    if extension not in allowed_extensions:\n",
    "        raise ValueError(f\"File extension {extension} is not allowed\")\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_contents = file.read()\n",
    "\n",
    "    if extension == \".pdf\":\n",
    "        file = await async_writer_client.files.upload(content=file_contents,\n",
    "                                                       content_disposition=f\"attachment; filename={name}{extension}\",\n",
    "                                                       content_type=\"application/octet-stream\")\n",
    "        file_text = await async_writer_client.tools.parse_pdf(file_id=file.id, format=\"text\")\n",
    "        await async_writer_client.files.delete(file.id)\n",
    "    else:\n",
    "        file_text = file_contents.decode(\"utf-8\")\n",
    "\n",
    "    return file_text\n",
    "\n",
    "\n",
    "async def repair_data(file_text: str, response_model: Type[BaseModel]) -> List[BaseModel]:\n",
    "    instructor_client = instructor.from_writer(client=async_writer_client)\n",
    "    entities_async_gen = await instructor_client.chat.completions.create(\n",
    "        model=\"palmyra-x5\",\n",
    "        response_model=Iterable[response_model],\n",
    "        max_retries=5,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Extract entities from {file_text}\"}]\n",
    "    )\n",
    "    \n",
    "    return [entity async for entity in entities_async_gen]\n",
    "\n",
    "\n",
    "def generate_csv(entities: List[BaseModel], response_model: Type[BaseModel], output_path: str = None) -> None:\n",
    "    fieldnames = list(response_model.model_json_schema()[\"properties\"].keys())\n",
    "    file_path = f\"{response_model.__name__}.csv\"\n",
    "    if output_path:\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        file_path = os.path.join(output_path, file_path)\n",
    "    with open(file_path, 'w') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for entity in entities:\n",
    "            writer.writerow(json.loads(response_model(**entity.model_dump()).model_dump_json()))\n",
    "\n",
    "\n",
    "async def handle_file(file_path: str, response_model: Type[BaseModel], output_path: str = None):\n",
    "    name, extension = os.path.splitext(os.path.basename(file_path))\n",
    "    file_text = await fetch_file_text(file_path, name, extension)\n",
    "    repaired_entities = await repair_data(file_text, response_model)\n",
    "    print(f\"Extracted {len(repaired_entities)} entities from {file_path}\")\n",
    "    generate_csv(repaired_entities, response_model, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main_example",
   "metadata": {},
   "source": [
    "## Running the data repair tool\n",
    "\n",
    "You can now process multiple files concurrently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "main_run",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 20 entities from example_data/AnotherExampleFileTextFormat.txt\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    data = [\n",
    "        # (\"example_data/ExampleFileTextFormat.txt\", UserExtract, None),\n",
    "        (\"example_data/AnotherExampleFileTextFormat.txt\", UserExtract, \"out/\"),\n",
    "    ]\n",
    "    tasks = [handle_file(file, model, path) for file, model, path in data]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
