{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8aa907f876bb781",
   "metadata": {},
   "source": [
    "[Model delegation](https://dev.writer.com/api-guides/model-delegation) allows you to delegate specific tasks to an domain-specific LLM during a chat. It uses a predefined [LLM tool](https://dev.writer.com/api-guides/model-delegation#tool-object) that you can pass when chatting with a general model.\n",
    "\n",
    "This cookbook shows how to use model delegation to refer medical questions to the [Palmyra-Med](https://dev.writer.com/models/palmyra-med) model during a chat.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before getting started, you'll need:\n",
    "\n",
    "- A [Writer AI Studio](https://app.writer.com/aistudio/signup?utm_campaign=devrel) account\n",
    "- An API key, which you can obtain by following the [API Quickstart](https://dev.writer.com/api-guides/quickstart)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install the Writer SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05643760cecc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU writer-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9312e9a13f5e5",
   "metadata": {},
   "source": [
    "Next, set the `WRITER_API_KEY` environment variable. We recommend setting it in a `.env` file in the root of your project, but this tutorial will set it in an environment variable if you don't have a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ea1629cdbb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from writerai import Writer\n",
    "\n",
    "if not os.getenv(\"WRITER_API_KEY\"):\n",
    "    os.environ[\"WRITER_API_KEY\"] = getpass.getpass(\"Enter your Writer API key: \")\n",
    "\n",
    "client = Writer()  # The Writer client automatically uses the WRITER_API_KEY environment variable to authenticate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608bb9b23a5498e",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "You've now initialized the Writer client and can use it to create a chat with an AI model.\n",
    "\n",
    "First, define the tools you want to provide to the LLM. In this example, you [define a tool](https://dev.writer.com/api-guides/model-delegation#tool-object) to use [Palmyra-Med](https://dev.writer.com/models/palmyra-med) to answer medical questions.\n",
    "\n",
    "The `type` field for the tool is `llm`. In the `function` field, the `model` is the ID of the [Palmyra model](https://dev.writer.com/home/models) you want to use. The `description` field describes when the tool should be used.\n",
    "\n",
    "> **Best practice:** The `description` field should indicate that the tool is an LLM. It should specify what the LLM is specialised in and when the tool should be used. The example below is a good description for a tool that invokes a medical LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83436249b52de650",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"llm\",\n",
    "        \"function\": {\n",
    "            \"description\": \"A function that will invoke the llm identified by the given model, \"\n",
    "                \"specialised in answering medical queries. Any user request asking for \"\n",
    "                \"medical advice should use this tool.\",\n",
    "            \"model\": \"palmyra-med\",\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9a4b2",
   "metadata": {},
   "source": [
    "Once you've defined the LLM tool, you can provide them to the LLM in the `tools` parameter when you create a chat.\n",
    "\n",
    "In this example, you are asking a medical question, so the general chat model will delegate the task to the medical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8fa2dcb1338c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.chat(\n",
    "    model=\"palmyra-x-004\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I feel pain in my lower knee after running. How do I treat it?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e35f15",
   "metadata": {},
   "source": [
    "The output includes the response from the medical model. \n",
    "\n",
    "The `response.choices[0].message.llm_data` field indicates that the response comes from an LLM tool call. It shows the model that was used to generate the response and the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a479ce5105a38dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.llm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c02882eaeab4e",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "The Writer client also supports streaming responses. In this example, you stream the chat response and collect the output text as it streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712760c15025b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_stream = client.chat.chat(\n",
    "    model=\"palmyra-x-004\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I feel pain in my lower knee after running. How do I treat it?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "output_text = \"\"\n",
    "\n",
    "for chunk in response_stream:\n",
    "    if chunk.choices[0].delta.content:\n",
    "        output_text += chunk.choices[0].delta.content\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
