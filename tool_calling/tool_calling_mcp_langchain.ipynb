{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84cc21c-aa85-4bc4-92dc-8b381d5b52b0",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- A [WRITER AI Studio](https://app.writer.com/register) account\n",
    "- An API key, which you can obtain by following the [API Quickstart](https://dev.writer.com/api-guides/quickstart)\n",
    "- Basic familiarity with Python and [AWS Strands](https://dev.writer.com/home/integrations/strands)\n",
    "\n",
    "## Installation and setup\n",
    "\n",
    "First, we need to install the WRITER SDK MCP package globally using npm. This provides the MCP server that will allow us to interact with WRITER's AI tools and services.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736a4a2-4b42-4f98-b752-8317e52c11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!npm install -g writer-sdk-mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f886d93-c098-4164-9c95-6becb4237927",
   "metadata": {},
   "source": [
    "Next, set the `WRITER_API_KEY` environment variable. We recommend setting it in a `.env` file in the root of your project, but this tutorial will set it in an environment variable if you don't have a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5362bf-bade-4c32-9d0f-5630303d2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"WRITER_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40e149-67fb-4fa8-a89d-f9d260f21c53",
   "metadata": {},
   "source": [
    "## Starting the MCP server\n",
    "\n",
    "Now we'll start the WRITER MCP server on port 3000. This server acts as a bridge between our Python code and WRITER's services, providing access to tools like content generation, knowledge graphs, file processing, and more. The server runs in the background using subprocess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1aa09-7954-440f-ba4a-c25670908396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Start MCP server on port 3000 (can change if needed)\n",
    "server = subprocess.Popen(\n",
    "    [\"npx\", \"-y\", \"writer-sdk-mcp\", \"--transport=http\", \"--port=3000\"],\n",
    "    env=os.environ,\n",
    ")\n",
    "print(\"‚úÖ WRITER MCP Server running at http://localhost:3000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b61bab3-c756-43b4-a68c-93d191d58233",
   "metadata": {},
   "source": [
    "## Example: Building an Assistant with WRITER + LangChain SDK\n",
    "\n",
    "For this example, we‚Äôll create a simple assistant using the [**WRITER LangChain SDK integration**](https://dev.writer.com/home/integrations/langchain), which connects the **WRITER MCP SDK** (Python package) to the **LangChain framework**.  \n",
    "\n",
    "This setup allows your LangChain agents to call WRITER‚Äôs MCP tools directly through the [**LangChain MCP integration**](https://docs.langchain.com/oss/python/langchain/mcp).\n",
    "\n",
    "### Python dependencies\n",
    "\n",
    "We'll install **LangChain** with the **WRITER MCP integration**, which gives us:\n",
    "- **`langchain`** ‚Äì The AI agent framework for building and orchestrating agents.  \n",
    "- **`langchain-mcp-adapters`** ‚Äì Integration to connect LangChain agents to WRITER‚Äôs MCP tools.  \n",
    "- **`langchain-writer`** ‚Äì Access WRITER models like Palmyra X5 from LangChain agents.  \n",
    "\n",
    "Let's start with the installations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a50a9ea-ebc6-4ca4-92d6-4f3cba3491be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b3e6d-de76-4b0c-8083-24f79a141f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cb06e-ebca-4882-8fc2-21a88bac3849",
   "metadata": {},
   "source": [
    "## System prompt configuration\n",
    "\n",
    "Here we define the system prompt that guides the Strands Agent‚Äôs behavior.\n",
    "This prompt instructs the agent to:\n",
    "- Act autonomously in reading, writing, and analyzing information.\n",
    "- Use WRITER‚Äôs MCP-connected tools for file processing, editing, and knowledge graph interactions, etc.\n",
    "- Provide clear, human-readable explanations and summaries of its work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03a86b-dafc-463c-9ff3-c225f560f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a research and writing assistant built on the WRITER SDK and connected to the Model Control Protocol (MCP).\n",
    "\n",
    "Your goals:\n",
    "1. Help users research technical, creative, or analytical topics.\n",
    "2. Produce clear, accurate, and well-structured text.\n",
    "3. When using tools, explain what you‚Äôre doing and why, unless instructed otherwise.\n",
    "4. Be concise and factual in tone.\n",
    "\n",
    "Always prioritize correctness, clarity, and tool-assisted reasoning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b1a73-85ec-44b8-952f-7eeb14a1e9d1",
   "metadata": {},
   "source": [
    "## Creating the Agent\n",
    "\n",
    "This code creates a `LangChainWriterAgent` class that:\n",
    "\n",
    "- Connects to a local MCP server running on port 3000.\n",
    "- Uses WRITER‚Äôs Palmyra X5 model for natural language processing and reasoning.\n",
    "- Connects the model to the `MultiServerMCPClient`, enabling access to available tools.\n",
    "- Provides an interactive chat interface for research and development tasks using LangChain.\n",
    "\n",
    "The agent can help you research technical, creative, or analytical topics, and can also invoke WRITER MCP tools directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686239e8-26fe-453d-ac4d-8044e66b3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import create_agent\n",
    "from langchain_writer import ChatWriter\n",
    "\n",
    "# Make sure your WRITER_API_KEY is set\n",
    "os.environ[\"WRITER_API_KEY\"] = os.getenv(\"WRITER_API_KEY\", \"YOUR_API_KEY_HERE\")\n",
    "\n",
    "class LangChainWriterAgent:\n",
    "    \"\"\"Lightweight research agent using WRITER's MCP tools via LangChain.\"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt: str, server, mcp_url=\"http://localhost:3000\"):\n",
    "\n",
    "        # Connect to MCP\n",
    "        self.client = MultiServerMCPClient(\n",
    "            {\n",
    "                \"research\": {\n",
    "                    \"transport\": \"streamable_http\",\n",
    "                    \"url\": mcp_url,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        self.model = ChatWriter(model=\"palmyra-x5\")\n",
    "        self.system_prompt = system_prompt\n",
    "        self.agent = None\n",
    "        self.server = server\n",
    "\n",
    "    async def init_agent(self):\n",
    "        \"\"\"Initialize LangChain agent with tools from MCP.\"\"\"\n",
    "        tools = await self.client.get_tools()\n",
    "        self.agent = create_agent(self.model, tools, system_prompt=self.system_prompt)\n",
    "\n",
    "    async def chat(self, query: str) -> str:\n",
    "        \"\"\"Send a query to the agent and stream results.\"\"\"\n",
    "        if not self.agent:\n",
    "            await self.init_agent()\n",
    "\n",
    "        final_response = \"\"\n",
    "        async for chunk in self.agent.astream(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "            stream_mode=\"updates\"\n",
    "        ):\n",
    "            for step, data in chunk.items():\n",
    "                text = data['messages'][-1].content_blocks[0]['text']\n",
    "                print(text)\n",
    "                final_response += text\n",
    "        return final_response\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the MCP server.\"\"\"\n",
    "        self.server.terminate()\n",
    "        self.server.wait()\n",
    "        print(\"üõë WRITER MCP Server stopped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dac6c5-428e-43d9-85f8-b41c18cfcdc4",
   "metadata": {},
   "source": [
    "### Using the Agent\n",
    "\n",
    "Initialize the `LangChainWriterAgent` to connect the WRITER MCP package with LangChain. This lets your local agent use WRITER‚Äôs MCP tools through the Palmyra model interface.\n",
    "\n",
    "**Try this query:**\n",
    "\n",
    "> ‚ÄúTell me about no-code apps‚Äîwhat they are, how they work (general description, do not share names of no-code agents), and which model versions I can use.‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b906e1-e822-4822-8c89-d5d4a904e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def main():\n",
    "    system_prompt = \"\"\"\n",
    "You are a research and writing assistant built on the WRITER SDK and connected to the Model Control Protocol (MCP).\n",
    "\n",
    "Your goals:\n",
    "1. Help users research technical, creative, or analytical topics.\n",
    "2. Produce clear, accurate, and well-structured text.\n",
    "3. When using tools, explain what you‚Äôre doing and why.\n",
    "4. Be concise and factual in tone.\n",
    "\"\"\"\n",
    "    agent = LangChainWriterAgent(system_prompt=system_prompt, server=server)\n",
    "    try:\n",
    "        query = \"Tell me about no-code apps‚Äîwhat they are, how they work (general, do not share names of no-code agents), and which model versions I can use.\"\n",
    "        response = await agent.chat(query)\n",
    "        print(\"\\n\\n‚úÖ Final Response:\\n\", response)\n",
    "    finally:\n",
    "        agent.stop()\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545b0f6-e1b2-4650-9c02-5fb60394c689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
