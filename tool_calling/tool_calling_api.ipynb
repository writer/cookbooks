{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tool calling in Writer**\n",
    "\n",
    "**_Tool calling_** is a way for Palmyra (the Writer family of LLMs) to call on external tools — hence the name — in order to perform specific tasks that the it can’t do by itself. These tasks include things like making API calls, performing calculations, or accessing external information. This cookbook shows how to use tool calling with Writer’s chat completion API to build AI applications that can provide better results than standard LLM-powered apps.\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Setup](#setup)\n",
    "- [Define your functions](#define-your-functions)\n",
    "- [Define the schema for your functions](#define-the-schema-for-your-functions)\n",
    "- [Build an app that uses tool calling](#build-an-app-that-uses-tool-calling)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Why would I want to use tool calling?\n",
    "\n",
    "With tool calling, Palmyra is given a set of tools that it can call on — hence the name — to enhance its capabilities so that it can provide more useful responses to users. These tools are registered with the LLM, so that it “knows” that they’re available. When the LLM receives a request, it “decides” if it needs to call on a tool for extra information or to take some kind of action based on the conversation it’s having.\n",
    "\n",
    "Some reasons for using tool calling:\n",
    "\n",
    "- **It allows for more accurate results than unassisted natural language generation can provide.** Tool calling works especially well for accessing up-to-date information, performing calculations or computation, and working with quantities. It can prevent the error many LLMs make when asked [“How many times does the letter ‘r’ appear in ‘strawberry?’”](https://www.inc.com/kit-eaton/how-many-rs-in-strawberry-this-ai-cant-tell-you.html)\n",
    "- **It extends what the model can do.** With tool calling, a model can provide results that wouldn’t be possible if it used only its training data by calling external APIs or services, accessing databases, or interacting with your organization’s systems.\n",
    "- **Automation.** Tool calling can automate workflows or trigger actions, making the model useful in a wide range of applications, from e-commerce to customer service.\n",
    "\n",
    "### Functions as tools\n",
    "\n",
    "One of the tool categories available to Palmyra are functions — and by functions, we mean the kind used in programming languages. As the developer of a Palmyra-powered application, you would define these functions and then define a _schema_, which is a data structure that acts as a catalog of tools that Palmyra can call for your application. The schema lists the available tools, the information they might require, and the results they produce.\n",
    "\n",
    "In the case where the tools are functions, the schema specifies the available functions, what arguments they might take, and what values they return.\n",
    "\n",
    "### How does tool calling work?\n",
    "Here’s a quick description of how it works:\n",
    "\n",
    "1. **User request**: The user asks for something that requires an external tool, such as “What's the current weather in Paris?”. \n",
    "2. **Model decides**: Based on the user’s input, the LLM recognizes that it needs a tool — in the case of our example, a way to get the weather at a specific location — to fulfill the request.\n",
    "3. **Tool call**: The LLM generates a command or request to call the appropriate tool, and if necessary, it generates any needed parameters. In our example, the tool is a function that can access a weather API, and the necessary parameter is “Paris”.\n",
    "4. **Tool response**: The tool processes the request and sends back the needed information. In our example, this information is the current weather in Paris.\n",
    "5. **Model response**: The LLM uses the information from the tool to generate a response to the user's request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "This notebook uses the following packages:\n",
    "\n",
    "* `geopy`: For the Nominatim geocoder, to convert addresses and place names into latitudes and longitudes.\n",
    "* `python-dotenv`: To load environment variables.\n",
    "* `requests`: To make API calls to IpInfo (user location from IP address) and Open-Meteo (weather).\n",
    "* `writer-sdk`: To makes calls to the Writer API.\n",
    "\n",
    "Run the cell below ensure you have these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "The cell below performs the initialization required for this notebook including the creation of an instance of the `Writer` object to interact with the LLM.\n",
    "\n",
    "To create a Writer client object, you need an API key. [You can sign up for one for free](https://app.writer.com/register). \n",
    "\n",
    "Once you have an API key, we recommend that you store it as an environment variable in a `.env` file like so:\n",
    "\n",
    "```\n",
    "WRITER_API_KEY=\"{Your Writer API key goes here}\"\n",
    "```\n",
    "\n",
    "When you instantiate the client with `client = Writer()`, the newly-created object will automatically look for an environment variable named `WRITER_API_KEY` and will complete the instantiation if an only if `WRITER_API_KEY` has been defined. This notebook uses the [python-dotenv] library to automatically define environment variables based on the contents of an `.env` file in the same directory.\n",
    "\n",
    "The `Writer()` initializer method also has an `api_key` parameter that you can use like this...\n",
    "\n",
    "```\n",
    "client = Writer(api_key=\"{Your Writer API key goes here}\")\n",
    "```\n",
    "\n",
    "...but we strongly encourage you not to leave API keys in your source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell before running any other cells in this cookbook!\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests\n",
    "from writerai import Writer\n",
    "\n",
    "# Load environment variables from .env file\n",
    "%reload_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "client = Writer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your functions**\n",
    "\n",
    "The next step is to define some functions for the model to call. Let’s define two functions:\n",
    "\n",
    "<table width=\"66%\">\n",
    "    <tr>\n",
    "        <th width=\"25%\" style=\"background-color: #5551ff; color: #ffffff;\">Function</th>\n",
    "        <th style=\"background-color: #5551ff; color: #ffffff;\">Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid #bfcbff;\"><code>get_location_from_ip()</code></td>\n",
    "        <td style=\"border: 1px solid #bfcbff;\">\n",
    "            <p>This function calls the [IPInfo](https://ipinfo.io/) service to determine the user’s location\n",
    "            based on their IP address.</p>\n",
    "            <p>We expect this function to be called when the user asks for their location or asks a question\n",
    "            along the lines of “Where am I?”</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid #bfcbff;\"><code>get_weather_at_location()</code></td>\n",
    "        <td style=\"border: 1px solid #bfcbff;\">\n",
    "            <p>This function call the [Open-Meteo](https://open-meteo.com/) API, which takes a latitude and longitude and\n",
    "            returns the current weather at those coordinates. It also uses the [Nominatim](https://nominatim.org/) geocoder\n",
    "            to convert place names and addresses into latitudes and longitudes.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`get_location_from_ip()`**\n",
    "\n",
    "Returns the user’s location based on their IP address using the [IPInfo](https://ipinfo.io/) service.\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "This function requires the following packages:\n",
    "\n",
    "- [`requests`](https://pypi.org/project/requests/)\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "None.\n",
    "\n",
    "\n",
    "#### Returns\n",
    "\n",
    "Dictionary with the following keys:\n",
    "\n",
    "- **`\"city\"`** (`str`): The city in which the user is located if it can be determined, or \"Unknown\" if not.\n",
    "- **`\"region\"`** (`str`): The region (state or province) in which the user is located if it can be determined, or \"Unknown\" if not.\n",
    "- **`\"country\"`** (`str`): The country in which the user is located if it can be determined, or \"Unknown\" if not.\n",
    "\n",
    "\n",
    "### Examples\n",
    "\n",
    "```\n",
    ">>> get_location_from_ip() # Tampa, Florida, USA\n",
    "{'city': 'Tampa', 'region': 'Florida', 'country': 'US'}\n",
    "\n",
    ">>> get_location_from_ip() # VPN server in Milan, Italy\n",
    "{'city': 'Milan', 'region': 'Lombardy', 'country': 'IT'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location_from_ip():\n",
    "    response = requests.get(\"https://ipinfo.io\")\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"city\"    : data.get(\"city\", \"Unknown\"), \n",
    "            \"region\"  : data.get(\"region\", \"Unknown\"), \n",
    "            \"country\" : data.get(\"country\", \"Unknown\"),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"city\"    : \"Unknown\", \n",
    "            \"region\"  : \"Unknown\", \n",
    "            \"country\" : \"Unknown\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`get_weather_at_location()`**\n",
    "\n",
    "Returns the current weather for a given location, specifically:\n",
    "\n",
    "- Current weather conditions (e.g. \"clear sky\", \"overcast\", \"moderate rain\"...)\n",
    "- Cloud cover percentage\n",
    "- Temperature (defaults to Celsius)\n",
    "- Humidity percentage\n",
    "\n",
    "The weather information is formatted to be easily understood by an LLM (and humans too!) and includes units where appropriate in order to avoid any ambiguity.\n",
    "\n",
    "This function gets its weather information from [Open-Meteo](https://open-meteo.com/), an open source weather API that can be access for free for non-commercial use. Open-Meteo requires a latitude and longitude as input, so this function uses the [Nominatim](https://nominatim.org/) geocoder, which uses [OpenStreetMap](https://www.openstreetmap.org/) data to convert human-friendly location names (which could be a reasonably well-known place, building, or landmark, a street address, or city) into those values.\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "This function requires the following packages:\n",
    "\n",
    "- [`geopy`](https://pypi.org/project/geopy/) for the `Nominatim` geocoder (import it like so: `from geopy.geocoders import Nominatim`)\n",
    "- [`requests`](https://pypi.org/project/requests/)\n",
    "\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "- **`location_name`** (`str`): \n",
    "Name of the place for which the weather is requested. This can be as specific as an address, but should at least specify a city. It can also be a reasonably well-known place (for example, the roadside attraction [“Carhenge”](https://carhenge.com/) works). Basically, any location known to OpenStreetMap will work.\n",
    "- **`use_metric_units`** (`bool`, defaults to `False`):\n",
    "Set to `True` if you want the temperature in Celsius and wind speed in kilometers per hour; otherwise it defaults to returning the temperature in degrees Fahrenheit and wind speed in miles per hour.\n",
    "\n",
    "\n",
    "#### Returns\n",
    "\n",
    "Dictionary with the following keys:\n",
    "\n",
    "- **`\"weather\"`** (`str`): One of the values from the `WEATHER_CODE_TABLE` dictionary (defined in the function).\n",
    "- **`\"cloud_cover\"`** (`str`): Cloud cover, expressed as a percentage (an integer in the 0 - 100 range followed by a \"%\" character).\n",
    "- **`\"temperature\"`** (`str`): Temperature expressed to 1 decimal point of accuracy followed by “degrees C” or “degrees F”, depending on the value of `use_metric_units`.\n",
    "- **`\"wind_speed\"`** (`str`): Wind speed expressed to 1 decimal point of accuracy followed by “km/h” or “mph”, depending on the value of `use_metric_units`.\n",
    "- **`\"humidity\"`** (`str`): Humidity, expressed as a percentage (an integer in the 0 - 100 range followed by a \"%\" character).\n",
    "\n",
    "\n",
    "#### Examples\n",
    "\n",
    "```\n",
    ">>> get_weather_at_location(\"New York City\")\n",
    "{'weather': 'partly cloudy',\n",
    " 'cloud_cover': '62%',\n",
    " 'temperature': '66.9 degrees F',\n",
    " 'wind_speed': '2.5 mph',\n",
    " 'humidity': '69%'}\n",
    "\n",
    ">>> get_weather_at_location(\"Eiffel Tower\", use_metric_units=True)\n",
    "{'weather': 'partly cloudy',\n",
    " 'cloud_cover': '54%',\n",
    " 'temperature': '13.8 degrees C',\n",
    " 'wind_speed': '7.1 km/h',\n",
    " 'humidity': '93%'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_at_location(location_name, use_metric_units=False):\n",
    "\n",
    "    WEATHER_CODE_TABLE = {\n",
    "        0:  \"clear sky\",\n",
    "        1:  \"mainly clear\", \n",
    "        2:  \"partly cloudy\",\n",
    "        3:  \"overcast\",\n",
    "        45: \"fog\",\n",
    "        48: \"depositing rime fog\",\n",
    "        51: \"light drizzle\",\n",
    "        53: \"moderate drizzle\",\n",
    "        55: \"dense drizzle\",\n",
    "        56: \"light freezing drizzle\",\n",
    "        57: \"dense freezing drizzle\",\n",
    "        61: \"slight rain\",\n",
    "        63: \"moderate rain\",\n",
    "        65: \"heavy rain\",\n",
    "        66: \"light freezing rain\",\n",
    "        67: \"heavy freezing rain\",\n",
    "        71: \"slight snow\",\n",
    "        73: \"moderate snow\",\n",
    "        75: \"heavy snow\",\n",
    "        77: \"snow grains\",\n",
    "        80: \"light rain showers\",\n",
    "        81: \"moderate rain showers\",\n",
    "        82: \"violent rain showers\",\n",
    "        85: \"slight snow showers\",\n",
    "        86: \"heavy snow showers\",\n",
    "        95: \"thunderstorm\",\n",
    "        96: \"thunderstorm with slight hail\",\n",
    "        99: \"thunderstorm with heavy hail\",\n",
    "    }\n",
    "\n",
    "    def location_name_to_latlong(location_name):\n",
    "        geolocator = Nominatim(user_agent=\"Writer.com tool calling demo notebook\")\n",
    "        location = geolocator.geocode(location_name)\n",
    "        return (location.latitude, location.longitude)\n",
    "\n",
    "    def celsius_to_fahrenheit(degrees_celsius):\n",
    "        return (degrees_celsius * 1.8) + 32\n",
    "\n",
    "    def kmh_to_mph(kmh):\n",
    "        return kmh * 0.621371\n",
    "\n",
    "    latitude, longitude = location_name_to_latlong(location_name)\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,relativehumidity_2m,weathercode,cloudcover,wind_speed_10m\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return {\n",
    "        \"weather\"     : WEATHER_CODE_TABLE.get(data[\"current\"][\"weathercode\"], \"unknown\"),\n",
    "        \"cloud_cover\" : f\"{data['current']['cloudcover']}%\",\n",
    "        \"temperature\" : (f\"{data['current']['temperature_2m']:.1f} degrees C\" if use_metric_units \n",
    "                         else f\"{celsius_to_fahrenheit(data['current']['temperature_2m']):.1f} degrees F\"),\n",
    "        \"wind_speed\"  : (f\"{data['current']['wind_speed_10m']:.1f} km/h\" if use_metric_units\n",
    "                         else f\"{kmh_to_mph(data['current']['wind_speed_10m']):.1f} mph\"),\n",
    "        \"humidity\"    : f\"{data['current']['relativehumidity_2m']}%\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define the schema for your functions**\n",
    "\n",
    "In order for the model to call the functions you defined, it needs to know:\n",
    "\n",
    "* That your application is providing functions that it can call.\n",
    "* The names of those functions.\n",
    "* The descriptions of what the functions do or what they are for.\n",
    "* The parameters that those function accept, and which ones are required.\n",
    "\n",
    "When the model receives a prompt, it will analyzes that prompt and determine if it can be matched to a function in the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_location_from_ip\",\n",
    "            \"description\": \"Get the user's location based on their IP address. If the user asks where they are or says they're lost, use this.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather_at_location\",\n",
    "            \"description\": \"Get the current weather for a given location, which may be a street address, the name of a building, landmark, or destination, or a city.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A location, such as an address, a city and province or state with country, or even the name of a reasonably well-known place.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"location\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build an app that uses tool calling**\n",
    "\n",
    "The cell below contains a basic multi-turn chat completion app. When you run it, you will be able to have an ongoing conversation with Palmyra until you enter a blank line, which stops the app. The app displays the number of prompts you have entered so far.\n",
    "\n",
    "The app maintains a record of the conversation in the `messages` list — both the user’s messages (the ones where the value of the `\"role\"` key is `\"user\"`), and Palmyra’s replies (messages where the value of the `\"role\"` key is `\"assistant\"`). You can see the contents of `messages` while the app is running by entering `!messages` as a prompt (it will not count as part of the conversation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_count = 1\n",
    "initial_system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a helpful assistant. Respond concisely and politely to user queries. Use clear, simple language. When asked for technical explanations, provide detailed and accurate information, but avoid jargon. If the user asks for assistance with a task, offer step-by-step guidance.\"\n",
    "}\n",
    "messages = [initial_system_message]\n",
    "\n",
    "print(\"\"\"\n",
    "Sample multi-turn chat completion app\n",
    "featuring tool calling\n",
    "=====================================\n",
    "\"\"\")\n",
    "temperature = float(input(\"Enter a temperature (0.0 - 2.0) for the chat, or just press 'Enter' for 1.0: \").strip() or 1.0)\n",
    "\n",
    "while True:\n",
    "    user_prompt = input(f\"[{user_prompt_count}]\\nEnter a prompt: \").strip()\n",
    "    if not user_prompt:\n",
    "        break\n",
    "\n",
    "    if user_prompt == \"!messages\":\n",
    "        print(f\"\\nContents of `messages` (this will not be included as part of the conversation):\")\n",
    "        print(\"-------------------------------------------------------------------------------\")\n",
    "        print(f\"{messages}\\n\\n\")\n",
    "        continue\n",
    "\n",
    "    user_prompt_count +=1\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "\n",
    "    # Make initial call to chat() function\n",
    "    # TODO: Replace this with the production SDK call\n",
    "    initial_response = client.chat.chat(\n",
    "        model=\"palmyra-x-004\", \n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        tools=tools, \n",
    "        tool_choice=\"auto\",\n",
    "        stream=False\n",
    "    )\n",
    "    initial_response_message = initial_response.choices[0].message\n",
    "    messages.append(initial_response_message)\n",
    "\n",
    "    # Make secondary call to chat() function\n",
    "    # if Palmyra decides that it needs to call a tool\n",
    "    tool_calls = initial_response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        for tool_call in tool_calls:\n",
    "            if tool_call.function.name == \"get_weather_at_location\":\n",
    "                location = eval(tool_call.function.arguments)[\"location\"]\n",
    "                function_response = get_weather_at_location(location)\n",
    "            if tool_call.function.name == \"get_location_from_ip\":\n",
    "                function_response = get_location_from_ip()\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"name\": tool_call.function.name,\n",
    "                \"content\": str(function_response),\n",
    "            })\n",
    "\n",
    "        final_response = client.chat.chat( \n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            model=\"palmyra-x-004\",\n",
    "            stream=False\n",
    "        )\n",
    "        final_response_message = {\n",
    "            \"role\": final_response.choices[0].message.role,\n",
    "            \"content\": final_response.choices[0].message.content\n",
    "        }\n",
    "        messages.append(final_response_message)\n",
    "        print(f\"\\n{final_response.choices[0].message.content}\\n\")\n",
    "    else:\n",
    "        print(f\"\\n{final_response.choices[0].message.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about tool calling, check out the [tool calling guide](https://dev.writer.com/api-guides/tool-calling) on the Writer docs.\n",
    "\n",
    "### Notes\n",
    "\n",
    "In the code above, there are _two_ calls to the chat completion API’s `chat()` method. The first one always executes:\n",
    "\n",
    "```python\n",
    "initial_response = client.chat.chat(\n",
    "    model=\"palmyra-x-004\", \n",
    "    messages=messages,\n",
    "    temperature=temperature,\n",
    "    tools=tools, \n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "```\n",
    "\n",
    "This looks like the standard call to `chat()`, but with a couple of extra parameters:\n",
    "\n",
    "<table width=\"66%\">\n",
    "    <tr>\n",
    "        <th width=\"25%\" style=\"background-color: #5551ff; color: #ffffff;\">Parameter</th>\n",
    "        <th style=\"background-color: #5551ff; color: #ffffff;\">Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid #bfcbff;\"><code>tools</code></td>\n",
    "        <td style=\"border: 1px solid #bfcbff;\">The tool schema.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 1px solid #bfcbff;\"><code>tool_choice</code></td>\n",
    "        <td style=\"border: 1px solid #bfcbff;\">\n",
    "            Specifies the tool that Palmyra should use. Most of the time, you should simply set\n",
    "            this to `auto` to let Palmyra decide.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "If Palmyra decides that it needs to call a tool, the response message’s `tool_calls` property will contain a list. The code above iterates through the list to find out which function Palmyra decided to use and creates a new message with a `tool` role whose content is the function’s result. That message gets added to the list of messages for the conversation, which in turn is sent as part of the second call to `chat()`:\n",
    "\n",
    "```python\n",
    "final_response = client.chat.chat( \n",
    "    messages=messages,\n",
    "    temperature=temperature,\n",
    "    model=\"palmyra-x-004\"\n",
    ")\n",
    "```\n",
    "\n",
    "Note that this call _does not_ contain the `tools` or `tool_choice` parameters — it’s a regular `chat()` call. The app then displays the result of this call to `chat()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
